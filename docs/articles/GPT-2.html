<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>rinna 社が構築した GPT-2 モデルを使ってみる | Portfolio</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/VuePress/imgs/favicon.ico">
    <meta name="description" content="GPT-2を使ってみる">
    <meta name="google-site-verification" content="Rr04P_zo0dof8iLtrJOAPYgC-60eqppExk85NQCmxxI">
    
    <link rel="preload" href="/VuePress/assets/css/0.styles.7247df58.css" as="style"><link rel="preload" href="/VuePress/assets/js/app.5cddafec.js" as="script"><link rel="preload" href="/VuePress/assets/js/2.61f7f738.js" as="script"><link rel="preload" href="/VuePress/assets/js/7.34b2bcf8.js" as="script"><link rel="prefetch" href="/VuePress/assets/js/10.dd6b0531.js"><link rel="prefetch" href="/VuePress/assets/js/11.eb7ec6d3.js"><link rel="prefetch" href="/VuePress/assets/js/12.b882e681.js"><link rel="prefetch" href="/VuePress/assets/js/13.c4a85122.js"><link rel="prefetch" href="/VuePress/assets/js/14.a0ceda7f.js"><link rel="prefetch" href="/VuePress/assets/js/15.89585d14.js"><link rel="prefetch" href="/VuePress/assets/js/16.b4a3c8c7.js"><link rel="prefetch" href="/VuePress/assets/js/17.1a4a8790.js"><link rel="prefetch" href="/VuePress/assets/js/18.a3e48e6d.js"><link rel="prefetch" href="/VuePress/assets/js/19.8bdbcfdf.js"><link rel="prefetch" href="/VuePress/assets/js/20.7cab56ec.js"><link rel="prefetch" href="/VuePress/assets/js/21.24ce74a9.js"><link rel="prefetch" href="/VuePress/assets/js/22.63b18aaf.js"><link rel="prefetch" href="/VuePress/assets/js/23.25eb6115.js"><link rel="prefetch" href="/VuePress/assets/js/24.eaff43b0.js"><link rel="prefetch" href="/VuePress/assets/js/25.86865abd.js"><link rel="prefetch" href="/VuePress/assets/js/26.b0097c68.js"><link rel="prefetch" href="/VuePress/assets/js/27.13fcb9cb.js"><link rel="prefetch" href="/VuePress/assets/js/28.707e00ea.js"><link rel="prefetch" href="/VuePress/assets/js/29.e1aa2d8d.js"><link rel="prefetch" href="/VuePress/assets/js/3.11e4fd3f.js"><link rel="prefetch" href="/VuePress/assets/js/30.1570ceee.js"><link rel="prefetch" href="/VuePress/assets/js/31.8f8fa616.js"><link rel="prefetch" href="/VuePress/assets/js/32.40a9a225.js"><link rel="prefetch" href="/VuePress/assets/js/33.5d1a979d.js"><link rel="prefetch" href="/VuePress/assets/js/34.45db8bcb.js"><link rel="prefetch" href="/VuePress/assets/js/35.9835bb30.js"><link rel="prefetch" href="/VuePress/assets/js/4.1c23426c.js"><link rel="prefetch" href="/VuePress/assets/js/5.a499e8f8.js"><link rel="prefetch" href="/VuePress/assets/js/6.cb75b676.js"><link rel="prefetch" href="/VuePress/assets/js/8.5bb618b6.js"><link rel="prefetch" href="/VuePress/assets/js/9.7b7d5ecd.js">
    <link rel="stylesheet" href="/VuePress/assets/css/0.styles.7247df58.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/VuePress/" class="home-link router-link-active"><!----> <span class="site-name">Portfolio</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/VuePress/" class="nav-link">
  ホーム
</a></div><div class="nav-item"><a href="/VuePress/works/" class="nav-link">
  作品詳細
</a></div><div class="nav-item"><a href="/VuePress/articles/" class="nav-link router-link-active">
  記事
</a></div><div class="nav-item"><a href="/VuePress/others/" class="nav-link">
  その他
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/VuePress/" class="nav-link">
  ホーム
</a></div><div class="nav-item"><a href="/VuePress/works/" class="nav-link">
  作品詳細
</a></div><div class="nav-item"><a href="/VuePress/articles/" class="nav-link router-link-active">
  記事
</a></div><div class="nav-item"><a href="/VuePress/others/" class="nav-link">
  その他
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>rinna 社が構築した GPT-2 モデルを使ってみる</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/VuePress/articles/GPT-2.html#はじめに" class="sidebar-link">はじめに</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/VuePress/articles/GPT-2.html#gpt-2-について" class="sidebar-link">GPT-2 について</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/VuePress/articles/GPT-2.html#gpt-2のバージョン" class="sidebar-link">GPT-2のバージョン</a></li></ul></li><li><a href="/VuePress/articles/GPT-2.html#rinnna-社のモデル" class="sidebar-link">rinnna 社のモデル</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/VuePress/articles/GPT-2.html#開発環境" class="sidebar-link">開発環境</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/VuePress/articles/GPT-2.html#gpt-2-を使って文章を生成" class="sidebar-link">GPT-2 を使って文章を生成</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/VuePress/articles/GPT-2.html#ライブラリのインストール" class="sidebar-link">ライブラリのインストール</a></li><li class="sidebar-sub-header"><a href="/VuePress/articles/GPT-2.html#gpt-2-の設定" class="sidebar-link">GPT-2 の設定</a></li><li class="sidebar-sub-header"><a href="/VuePress/articles/GPT-2.html#文の生成" class="sidebar-link">文の生成</a></li></ul></li><li><a href="/VuePress/articles/GPT-2.html#gpu-対応" class="sidebar-link">GPU 対応</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/VuePress/articles/GPT-2.html#コードを書きかえる" class="sidebar-link">コードを書きかえる</a></li></ul></li><li><a href="/VuePress/articles/GPT-2.html#おわりに" class="sidebar-link">おわりに</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="rinna-社が構築した-gpt-2-モデルを使ってみる"><a href="#rinna-社が構築した-gpt-2-モデルを使ってみる" class="header-anchor">#</a> rinna 社が構築した GPT-2 モデルを使ってみる</h1> <h3 id="目次"><a href="#目次" class="header-anchor">#</a> 目次</h3> <p></p><div class="table-of-contents"><ul><li><a href="#はじめに">はじめに</a></li><li><a href="#gpt-2-について">GPT-2 について</a></li><li><a href="#rinnna-社のモデル">rinnna 社のモデル</a></li><li><a href="#開発環境">開発環境</a></li><li><a href="#gpt-2-を使って文章を生成">GPT-2 を使って文章を生成</a></li><li><a href="#gpu-対応">GPU 対応</a></li><li><a href="#おわりに">おわりに</a></li></ul></div><p></p> <h2 id="はじめに"><a href="#はじめに" class="header-anchor">#</a> はじめに</h2> <p>2022年 11月 30日に OpenAI が公開した ChatGPT が、公開 6 日目に 100 万ユーザを突破するなど、絶大的な人気を誇っています。そんな ChatGPT の性能の高さから、大規模言語モデルに興味を持って色々調べたところ、rinnna 社が構築した GPT-2 モデルが導入がし易そうだったので、使ってみることにしました。</p> <h2 id="gpt-2-について"><a href="#gpt-2-について" class="header-anchor">#</a> GPT-2 について</h2> <p>2019年 2月に OpenAI が発表した自然言語処理モデルです。</p> <p>元論文 : <a href="https://paperswithcode.com/paper/language-models-are-unsupervised-multitask" target="_blank" rel="noopener noreferrer">https://paperswithcode.com/paper/language-models-are-unsupervised-multitask<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>言語モデルとは、会話や文章などの尤もらしさを確率としてモデル化したもので、GPT-2 は単語レベルの確率の組み合わせから文の確率を計算する言語モデル（自己回帰言語モデル）です。</p> <p>GPT-2 は Transformer という RNN や CNN を用いない深層学習モデルをベースとしていて、事前学習やファインチューニングを行うことで高い精度の文書を生成できます。</p> <p>他に Transformer をベースとしているモデルだと、2018年 10月に登場した BERT が有名です。
BERT は Encoder を複数重ねていおり、文章の分類や単語の穴埋めなどが得意であるのに対し、GPT-2 は Decoder を重ねていて、文章の生成が得意です。</p> <p><img src="/VuePress/assets/img/3.774b0a99.png" alt="3"></p> <h3 id="gpt-2のバージョン"><a href="#gpt-2のバージョン" class="header-anchor">#</a> GPT-2のバージョン</h3> <p>GPT-2 には、OpenAI で公開された4つのバージョンがあります。</p> <ol><li>Small</li> <li>Medium</li> <li>Large</li> <li>X-Large</li></ol> <p>バージョンによって、デコーダーのレイヤー数、埋め込みサイズ、アテンションヘッドの数などが違います。モデルが大きいほど性能が高いです。</p> <p><img src="/VuePress/assets/img/4.7f15c9d0.png" alt="4"></p> <h2 id="rinnna-社のモデル"><a href="#rinnna-社のモデル" class="header-anchor">#</a> rinnna 社のモデル</h2> <p>rinna社が構築した GPT-2 大規模言語モデルは以下の通りです。</p> <table><thead><tr><th>language model</th> <th style="text-align:right;">layers</th> <th style="text-align:right;">params</th> <th style="text-align:right;">emb dim</th> <th style="text-align:right;">epochs</th> <th style="text-align:right;">dev ppl</th> <th style="text-align:center;">training time</th></tr></thead> <tbody><tr><td>japanese-gpt-1b</td> <td style="text-align:right;">1.3B</td> <td style="text-align:right;">24</td> <td style="text-align:right;">2048</td> <td style="text-align:right;">10+</td> <td style="text-align:right;">13.9</td> <td style="text-align:center;">n/a</td></tr> <tr><td>japanese-gpt2-medium</td> <td style="text-align:right;">336M</td> <td style="text-align:right;">24</td> <td style="text-align:right;">1024</td> <td style="text-align:right;">4</td> <td style="text-align:right;">18</td> <td style="text-align:center;">45 days</td></tr> <tr><td>japanese-gpt2-small</td> <td style="text-align:right;">110M</td> <td style="text-align:right;">12</td> <td style="text-align:right;">768</td> <td style="text-align:right;">3</td> <td style="text-align:right;">21</td> <td style="text-align:center;">15 days</td></tr> <tr><td>japanese-gpt2-xsmall</td> <td style="text-align:right;">37M</td> <td style="text-align:right;">6</td> <td style="text-align:right;">512</td> <td style="text-align:right;">3</td> <td style="text-align:right;">28</td> <td style="text-align:center;">4 days</td></tr></tbody></table> <p><a href="https://github.com/rinnakk/japanese-pretrained-models" target="_blank" rel="noopener noreferrer">https://github.com/rinnakk/japanese-pretrained-models<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> より引用</p> <p>今回は処理時間の関係上、文生成に japanese-gpt-1b を使ってみます。</p> <p>トレーニングコードは、<a href="https://github.com/rinnakk/japanese-gpt2" target="_blank" rel="noopener noreferrer">GitHub<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> と NLPモデルライブラリ <a href="https://huggingface.co/rinna" target="_blank" rel="noopener noreferrer">HuggingFace<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> で、オープンソースとして公開されています。</p> <h2 id="開発環境"><a href="#開発環境" class="header-anchor">#</a> 開発環境</h2> <p>今回は GPT-2 の試用が目的だったため、環境構築を必要としない Google Colaboratory を使いました。</p> <p>環境構築をする機会があったら、追記しようと思います。</p> <h2 id="gpt-2-を使って文章を生成"><a href="#gpt-2-を使って文章を生成" class="header-anchor">#</a> GPT-2 を使って文章を生成</h2> <p>GPT-2を使って文章を生成していきます。
前述したとおり、文章生成には <a href="https://huggingface.co/rinna/japanese-gpt-1b" target="_blank" rel="noopener noreferrer">japanese-gpt-1b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> を使っていきます。</p> <h3 id="ライブラリのインストール"><a href="#ライブラリのインストール" class="header-anchor">#</a> ライブラリのインストール</h3> <p>GPT-2 が含まれるライブラリ transformers をインストールします。
また、transformers.T5Tokenizer をテキストをトークンに分割する際に使用するのでライブラリ sentencepiece も一緒にインストールします。</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token operator">!</span>pip <span class="token function">install</span> transformers
<span class="token operator">!</span>pip <span class="token function">install</span> sentencepiece
</code></pre></div><h3 id="gpt-2-の設定"><a href="#gpt-2-の設定" class="header-anchor">#</a> GPT-2 の設定</h3> <p>テキストをトークンに分割するために T5Tokenizer を、訓練済みモデルの読み込みのために AutoModelForCausalLM を設定します。
japanese-gpt-1b を読み込みます。</p> <div class="language-py extra-class"><pre class="language-py"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> T5Tokenizer<span class="token punctuation">,</span> AutoModelForCausalLM

tokenizer <span class="token operator">=</span> T5Tokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;rinna/japanese-gpt-1b&quot;</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;rinna/japanese-gpt-1b&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="文の生成"><a href="#文の生成" class="header-anchor">#</a> 文の生成</h3> <p>最初の文章をトークナイザーを使って、モデルへの入力に変換します。
文書は『雪国』（川端康成著）の書き出しにしました。</p> <div class="language-py extra-class"><pre class="language-py"><code>text <span class="token operator">=</span> <span class="token string">&quot;国境の長いトンネルを抜けると雪国であった。&quot;</span>
<span class="token builtin">input</span> <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">,</span> add_special_tokens<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre></div><p>変換した入力を訓練済みのモデルに渡し、モデルの出力を受け取ります。
各設定は、テストコードの値をそのまま使っています。</p> <div class="language-py extra-class"><pre class="language-py"><code>output <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>
                        min_length<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>
                        max_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
                        do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                        top_k<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>
                        top_p<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">,</span>
                        num_return_sequences<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
                        pad_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">,</span>
                        bos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>bos_token_id<span class="token punctuation">,</span>
                        eos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>eos_token_id
                       <span class="token punctuation">)</span>
</code></pre></div><p>受け取った出力をトークナイザーを使って文章に変換し、表示します。</p> <div class="language-py extra-class"><pre class="language-py"><code>generated_sentence <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>output<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> sentence <span class="token keyword">in</span> generated_sentences<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
</code></pre></div><p>結果は以下の通りです。</p> <div class="language- extra-class"><pre class="language-text"><code>国境の長いトンネルを抜けると雪国であった。白かった。白銀の世界。銀世界が美しい。白い空と、白い雪。真っ白な世界。その中に、雪が降る。白く、静かに降る、銀の雨。白銀の光と、白い雪。
国境の長いトンネルを抜けると雪国であった。夜の東北道は予想通りかなりの渋滞。
国境の長いトンネルを抜けると雪国であった。夜の十一時である。トンネルを抜けると雪国であった。夜なので、雪は積もっていないが、車の中は極度に寒くなって目を覚ました。雪国なので、車の往来も少なく、前方の闇の中に列車のライトがぼんやりと差し込むのみである。外は深い雪におおわれている。車内は極度に寒くなり、毛布に包まって横になる。列車の走行音が、耳の中に響く。車内の温度も氷
</code></pre></div><p>かなり自然に文章が生成されていますね。
「num_return_sequences」を 3 に設定しているので、文章が 3 個生成されました。</p> <h2 id="gpu-対応"><a href="#gpu-対応" class="header-anchor">#</a> GPU 対応</h2> <h3 id="コードを書きかえる"><a href="#コードを書きかえる" class="header-anchor">#</a> コードを書きかえる</h3> <p>GPU で処理を行いたい場合は、コードを以下の通りに書きかえます。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> T5Tokenizer<span class="token punctuation">,</span> AutoModelForCausalLM

tokenizer <span class="token operator">=</span> T5Tokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;rinna/japanese-gpt-1b&quot;</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;rinna/japanese-gpt-1b&quot;</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span>

text <span class="token operator">=</span> <span class="token string">&quot;国境の長いトンネルを抜けると雪国であった。&quot;</span>
<span class="token builtin">input</span> <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">,</span> add_special_tokens<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    output <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>model<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>
                            min_length<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>
                            max_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
                            do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                            top_k<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>
                            top_p<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">,</span>
                            num_return_sequences<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
                            pad_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">,</span>
                            bos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>bos_token_id<span class="token punctuation">,</span>
                            eos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>eos_token_id
                        <span class="token punctuation">)</span>

generated_sentences <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>output<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> sentence <span class="token keyword">in</span> generated_sentences<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
</code></pre></div><p>一番初めに PyTorch をインポートします。</p> <h4 id="google-colaboratory-の設定"><a href="#google-colaboratory-の設定" class="header-anchor">#</a> Google Colaboratory の設定</h4> <p>Google Colaboratory で GPU を使用する場合は「ラインタイム」→「ランタイムのタイプを変更」→ハードウェア アクセラレータを「GPU」にします。</p> <p><img src="/VuePress/assets/img/1.af17d5d4.png" alt="1"> <img src="/VuePress/assets/img/2.90e70451.png" alt="2"></p> <h2 id="おわりに"><a href="#おわりに" class="header-anchor">#</a> おわりに</h2> <p>今回は rinnna 社が構築した GPT-2 モデルを使って文生成を行いました。時間に余裕ができたら、ファインチューニングも行い、追記しようと思います。</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">10ヶ月前</span></div></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/VuePress/assets/js/app.5cddafec.js" defer></script><script src="/VuePress/assets/js/2.61f7f738.js" defer></script><script src="/VuePress/assets/js/7.34b2bcf8.js" defer></script>
  </body>
</html>
